## Ollama with Fastapi running LLama3.2 inside a docker container


<div align="center">
<img src="./public/ollama.jpg" />
</div>


- Runs Ollama

- Runs LLama3.2:latest model (extendable)

- Open API Docs interface

## Clone
```
> git clone https://github.com/jwill9999/llama3.2.git

## Start the container
> docker compose up -d

## Stop the container
> docker compose down
```


## Start the container
> docker compose up -d

## Stop the container
> docker compose down

> Open API docs  http://localhost:8000/docs

> JSON response http://localhost:8000