## Ollama with fastapi running LLama3.2 inside a docker container
